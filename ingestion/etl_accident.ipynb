{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46003352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL de connexion construite : postgresql+psycopg2://user_securite_routiere:password123@localhost:5432/securite_routiere_db\n",
      "üéâ Connexion √† la base de donn√©es PostgreSQL r√©ussie !\n",
      "R√©sultat du test de lecture : 1\n"
     ]
    }
   ],
   "source": [
    "# Installer les biblioth√®ques\n",
    "#pip install jupyterlab pandas requests sqlalchemy psycopg2-binary geopandas\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from sqlalchemy import create_engine\n",
    "from shapely.geometry import Point\n",
    "import io\n",
    "\n",
    "# =====================================================================\n",
    "# BLOC DE CONNEXION \n",
    "# =====================================================================\n",
    "\n",
    "# 1. Importer la fonction 'create_engine' ET 'text' depuis sqlalchemy\n",
    "from sqlalchemy import create_engine, text\n",
    "import pandas as pd\n",
    "\n",
    "# 2. D√©finir nos 5 variables \n",
    "DB_USER = \"user_securite_routiere\"\n",
    "DB_PASSWORD = \"password123\"\n",
    "DB_HOST = \"localhost\"\n",
    "DB_PORT = \"5432\"\n",
    "DB_NAME = \"securite_routiere_db\"\n",
    "\n",
    "# 3. Construire l'URL de connexion \n",
    "DATABASE_URL = f'postgresql+psycopg2://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}'\n",
    "print(f\"URL de connexion construite : {DATABASE_URL}\")\n",
    "\n",
    "# 4. Cr√©er le moteur de connexion et tester\n",
    "try:\n",
    "    engine = create_engine(DATABASE_URL)\n",
    "    \n",
    "    # 5. TESTER LA CONNEXION \n",
    "    with engine.connect() as connection:\n",
    "        print(\"üéâ Connexion √† la base de donn√©es PostgreSQL r√©ussie !\")\n",
    "        \n",
    "        # Test suppl√©mentaire : lire le r√©sultat\n",
    "        result = connection.execute(text(\"SELECT 1\"))\n",
    "        \n",
    "        for row in result:\n",
    "            print(f\"R√©sultat du test de lecture : {row[0]}\") # On met row[0] pour n'afficher que le chiffre\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"‚ùå √âchec de la connexion √† la base de donn√©es.\")\n",
    "    print(f\"Erreur : {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd0132a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lancement du t√©l√©chargement. Veuillez patienter, cela peut prendre un moment...\n",
      "T√©l√©chargement termin√© avec succ√®s !\n",
      "------------------------------------------------------------\n",
      "Le DataFrame brut contient 475,911 lignes et 69 colonnes.\n",
      "------------------------------------------------------------\n",
      "Cr√©ation de la table 'bronze.accidents_raw' si elle n'existe pas...\n",
      "D√©but du chargement rapide des donn√©es dans la couche BRONZE avec COPY...\n",
      "Table 'bronze.accidents_raw' vid√©e.\n",
      "‚úÖ Succ√®s ! Les donn√©es ont √©t√© charg√©es dans la table 'bronze.accidents_raw'.\n"
     ]
    }
   ],
   "source": [
    "# =====================================================================\n",
    "# BLOC OPTIMIS√â : UTILISATION DE COPY POUR UN CHARGEMENT ULTRA-RAPIDE\n",
    "# =====================================================================\n",
    "import pandas as pd\n",
    "import requests\n",
    "import io\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# --- PARTIE 1 : CONNEXION A LA BASE DE DONNEES ---\n",
    "DB_USER = \"user_securite_routiere\"\n",
    "DB_PASSWORD = \"password123\"\n",
    "DB_HOST = \"localhost\"\n",
    "DB_PORT = \"5432\"\n",
    "DB_NAME = \"securite_routiere_db\"\n",
    "\n",
    "DATABASE_URL = f'postgresql+psycopg2://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}'\n",
    "engine = create_engine(DATABASE_URL)\n",
    "\n",
    "\n",
    "# --- PARTIE 2 : FONCTION DE TELECHARGEMENT  ---\n",
    "def download_data(url):\n",
    "    print(\"Lancement du t√©l√©chargement. Veuillez patienter, cela peut prendre un moment...\")\n",
    "    try:\n",
    "        response = requests.get(url, timeout=300)\n",
    "        response.raise_for_status()\n",
    "        csv_data = io.StringIO(response.text)\n",
    "        df = pd.read_csv(csv_data, sep=';', dtype=str) \n",
    "        print(\"T√©l√©chargement termin√© avec succ√®s !\")\n",
    "        print(\"-\" * 60)\n",
    "        print(f\"Le DataFrame brut contient {df.shape[0]:,} lignes et {df.shape[1]} colonnes.\")\n",
    "        print(\"-\" * 60)\n",
    "        return df\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Une erreur de connexion est survenue : {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Une erreur inattendue est survenue : {e}\")\n",
    "        return None\n",
    "\n",
    "# --- NOUVELLE FONCTION : CHARGEMENT RAPIDE AVEC COPY ---\n",
    "def copy_from_stringio(df, table_name, schema_name, connection):\n",
    "    \"\"\"\n",
    "    Charge un DataFrame dans une table PostgreSQL en utilisant la m√©thode COPY,\n",
    "    qui est beaucoup plus rapide pour de grands volumes de donn√©es.\n",
    "    \"\"\"\n",
    "    # 1. On utilise un buffer en m√©moire (StringIO) pour convertir le DataFrame en CSV\n",
    "    buffer = io.StringIO()\n",
    "    df.to_csv(buffer, index=False, header=False, sep=';')\n",
    "    buffer.seek(0) # On remet le curseur au d√©but du buffer pour la lecture\n",
    "    \n",
    "    # 2. On utilise la connexion bas-niveau de psycopg2 pour acc√©der √† la fonction COPY\n",
    "    raw_connection = connection.raw_connection()\n",
    "    cursor = raw_connection.cursor()\n",
    "    \n",
    "    # 3. On ex√©cute la commande COPY\n",
    "    #    On vide la table avant pour simuler le 'if_exists=replace'\n",
    "    full_table_name = f'{schema_name}.{table_name}'\n",
    "    cursor.execute(f\"TRUNCATE TABLE {full_table_name} RESTART IDENTITY;\")\n",
    "    print(f\"Table '{full_table_name}' vid√©e.\")\n",
    "    \n",
    "    cursor.copy_expert(\n",
    "        f\"\"\"COPY {full_table_name} FROM STDIN WITH (FORMAT CSV, DELIMITER ';')\"\"\",\n",
    "        buffer\n",
    "    )\n",
    "    \n",
    "    # 4. On valide la transaction\n",
    "    raw_connection.commit()\n",
    "    cursor.close()\n",
    "\n",
    "# --- PARTIE 3 : ORCHESTRATION DU CHARGEMENT \n",
    "try:\n",
    "    url_csv = \"https://public.opendatasoft.com/api/explore/v2.1/catalog/datasets/accidents-corporels-de-la-circulation-millesime/exports/csv?lang=fr&timezone=Europe%2FBerlin&use_labels=true&delimiter=%3B\"\n",
    "    df_raw = download_data(url_csv)\n",
    "\n",
    "    if df_raw is not None:\n",
    "        # On doit d'abord cr√©er la table avec les bonnes colonnes avant d'utiliser COPY\n",
    "        print(\"Cr√©ation de la table 'bronze.accidents_raw' si elle n'existe pas...\")\n",
    "        # On envoie juste l'en-t√™te pour que Pandas cr√©e la table avec la bonne structure\n",
    "        df_raw.head(0).to_sql('accidents_raw', engine, schema='bronze', if_exists='replace', index=False)\n",
    "        \n",
    "        print(\"D√©but du chargement rapide des donn√©es dans la couche BRONZE avec COPY...\")\n",
    "        # On appelle notre nouvelle fonction rapide !\n",
    "        copy_from_stringio(df_raw, 'accidents_raw', 'bronze', engine)\n",
    "\n",
    "        print(\"‚úÖ Succ√®s ! Les donn√©es ont √©t√© charg√©es dans la table 'bronze.accidents_raw'.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Une erreur est survenue pendant le processus de chargement : {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb27f724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================\n",
      "   Liste des colonnes du DataFrame des accidents   \n",
      "=====================================================\n",
      "\n",
      "Nombre total de colonnes : 69\n",
      "\n",
      "Identifiant de l'accident\n",
      "Date et heure\n",
      "Commune\n",
      "Ann√©e\n",
      "Mois\n",
      "Jour\n",
      "Heure minute\n",
      "Lumi√®re\n",
      "Localisation\n",
      "Intersection\n",
      "Conditions atmosph√©riques\n",
      "Collision\n",
      "D√©partement\n",
      "Code commune\n",
      "Code Insee\n",
      "Adresse\n",
      "Latitude\n",
      "Longitude\n",
      "Code Postal\n",
      "Num√©ro\n",
      "Coordonn√©es\n",
      "PR\n",
      "Surface\n",
      "V1\n",
      "Circulation\n",
      "Voie r√©serv√©e\n",
      "Env1\n",
      "Voie\n",
      "Largeur de la chauss√©e\n",
      "V2\n",
      "Largeur terre plein central\n",
      "Nombre de voies\n",
      "Cat√©gorie route\n",
      "PR1\n",
      "Plan\n",
      "Profil\n",
      "Infrastructure\n",
      "Situation\n",
      "Ann√©e de naissance\n",
      "Sexe\n",
      "Action pi√©ton\n",
      "Gravit√©\n",
      "Existence √©quipement de s√©curit√©\n",
      "Utilisation √©quipement de s√©curit√©\n",
      "Localisation du pi√©ton\n",
      "Identifiant v√©hicule\n",
      "Place\n",
      "Cat√©gorie d'usager\n",
      "Pi√©ton seul ou non\n",
      "Motif trajet\n",
      "Point de choc\n",
      "Man≈ìuvre\n",
      "Sens\n",
      "Obstacle mobile heurt√©\n",
      "Obstacle fixe heurt√©\n",
      "Cat√©gorie v√©hicule\n",
      "Nombre d'occupants\n",
      "Gps\n",
      "date\n",
      "year_georef\n",
      "Nom Officiel Commune\n",
      "Code Officiel D√©partement\n",
      "Nom Officiel D√©partement\n",
      "Code Officiel EPCI\n",
      "Nom Officiel EPCI\n",
      "Code Officiel R√©gion\n",
      "Nom Officiel R√©gion\n",
      "Nom Officiel Commune / Arrondissement Municipal\n",
      "Code Officiel Commune\n",
      "\n",
      "=====================================================\n"
     ]
    }
   ],
   "source": [
    "# Assurez-vous que la variable 'df_raw' existe bien apr√®s le t√©l√©chargement\n",
    "\n",
    "if 'df_raw' in locals() and df_raw is not None:\n",
    "    print(\"=====================================================\")\n",
    "    print(\"   Liste des colonnes du DataFrame des accidents   \")\n",
    "    print(\"=====================================================\")\n",
    "    \n",
    "    # R√©cup√©rer la liste des noms de colonnes\n",
    "    liste_des_colonnes = df_raw.columns.tolist()\n",
    "    \n",
    "    # Afficher le nombre total de colonnes pour information\n",
    "    print(f\"\\nNombre total de colonnes : {len(liste_des_colonnes)}\\n\")\n",
    "    \n",
    "    # Afficher chaque nom de colonne sur une nouvelle ligne pour une meilleure lisibilit√©\n",
    "    for nom_colonne in liste_des_colonnes:\n",
    "        print(nom_colonne)\n",
    "        \n",
    "    print(\"\\n=====================================================\")\n",
    "\n",
    "else:\n",
    "    print(\"Erreur : Le DataFrame 'df_raw' n'a pas √©t√© trouv√© ou est vide.\")\n",
    "    print(\"Veuillez d'abord ex√©cuter la cellule de t√©l√©chargement des donn√©es.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ffeae58b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_colonnes = {\n",
    "    # --- Caract√©ristiques de l'accident (12) ---\n",
    "    \"Identifiant de l'accident\": \"num_acc\",\n",
    "    \"Date et heure\": \"datetime\",\n",
    "    \"Ann√©e\": \"an\",\n",
    "    \"Mois\": \"mois\",\n",
    "    \"Jour\": \"jour\",\n",
    "    \"Heure minute\": \"hrmn\",\n",
    "    \"Lumi√®re\": \"lum\",\n",
    "    \"Localisation\": \"agg\",\n",
    "    \"Intersection\": \"int\",\n",
    "    \"Conditions atmosph√©riques\": \"atm\",\n",
    "    \"Collision\": \"col\",\n",
    "    \"Situation\": \"situ\",\n",
    "\n",
    "    # --- Lieu (30) ---\n",
    "    \"D√©partement\": \"dep\",\n",
    "    \"Code commune\": \"com\",\n",
    "    \"Code Insee\": \"insee\",\n",
    "    \"Adresse\": \"adr\",\n",
    "    \"Latitude\": \"lat\",\n",
    "    \"Longitude\": \"long\",\n",
    "    \"Code Postal\": \"code_postal\",\n",
    "    \"Num√©ro\": \"num\",\n",
    "    \"Coordonn√©es\": \"coordonnees\",\n",
    "    \"PR\": \"pr\",\n",
    "    \"Surface\": \"surf\",\n",
    "    \"V1\": \"v1\",\n",
    "    \"Circulation\": \"circ\",\n",
    "    \"Voie r√©serv√©e\": \"vosp\",\n",
    "    \"Env1\": \"env1\",\n",
    "    \"Voie\": \"voie\",\n",
    "    \"Largeur de la chauss√©e\": \"larrout\",\n",
    "    \"V2\": \"v2\",\n",
    "    \"Largeur terre plein central\": \"lartpc\",\n",
    "    \"Nombre de voies\": \"nbv\",\n",
    "    \"Cat√©gorie route\": \"catr\",\n",
    "    \"PR1\": \"pr1\",\n",
    "    \"Plan\": \"plan\",\n",
    "    \"Profil\": \"prof\",\n",
    "    \"Infrastructure\": \"infra\",\n",
    "    \"Gps\": \"gps\",\n",
    "    \"date\": \"date\", \n",
    "    \"year_georef\": \"year_georef\",\n",
    "    \"Commune\": \"nom_com\", \n",
    "    \"Nom Officiel Commune\": \"com_name\",\n",
    "\n",
    "    # --- Usager (11) ---\n",
    "    \"Ann√©e de naissance\": \"an_nais\",\n",
    "    \"Sexe\": \"sexe\",\n",
    "    \"Action pi√©ton\": \"actp\",\n",
    "    \"Gravit√©\": \"grav\",\n",
    "    \"Existence √©quipement de s√©curit√©\": \"secu\",\n",
    "    \"Utilisation √©quipement de s√©curit√©\": \"secu_utl\",\n",
    "    \"Localisation du pi√©ton\": \"locp\",\n",
    "    \"Place\": \"place\",\n",
    "    \"Cat√©gorie d'usager\": \"catu\",\n",
    "    \"Pi√©ton seul ou non\": \"etatp\",\n",
    "    \"Motif trajet\": \"trajet\",\n",
    "\n",
    "    # --- V√©hicule (8) ---\n",
    "    \"Identifiant v√©hicule\": \"num_veh\",\n",
    "    \"Point de choc\": \"choc\",\n",
    "    \"Man≈ìuvre\": \"manv\",\n",
    "    \"Sens\": \"senc\",\n",
    "    \"Obstacle mobile heurt√©\": \"obsm\",\n",
    "    \"Obstacle fixe heurt√©\": \"obs\",\n",
    "    \"Cat√©gorie v√©hicule\": \"catv\",\n",
    "    \"Nombre d'occupants\": \"occutc\",\n",
    "\n",
    "    # --- Noms et Codes Officiels (8) ---\n",
    "    \"Code Officiel D√©partement\": \"dep_code\", \n",
    "    \"Nom Officiel D√©partement\": \"dep_name\",\n",
    "    \"Code Officiel EPCI\": \"epci_code\",       \n",
    "    \"Nom Officiel EPCI\": \"epci_name\",\n",
    "    \"Code Officiel R√©gion\": \"reg_code\",       \n",
    "    \"Nom Officiel R√©gion\": \"reg_name\",\n",
    "    \"Nom Officiel Commune / Arrondissement Municipal\": \"com_arm_name\",\n",
    "    \"Code Officiel Commune\": \"code_com\"         \n",
    "}\n",
    "\n",
    "len(mapping_colonnes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b440b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D√©but du processus de transformation Bronze -> Silver...\n",
      "Utilisation de l'objet de connexion 'engine' existant.\n",
      "\n",
      "Lecture des donn√©es depuis la table 'bronze.accidents_raw'...\n",
      "475,911 lignes lues avec succ√®s.\n",
      "\n",
      "Renommage des colonnes en utilisant le dictionnaire fourni...\n",
      "Colonnes renomm√©es avec succ√®s.\n",
      "Nouveaux noms de colonnes : ['num_acc', 'datetime', 'nom_com', 'an', 'mois', 'jour', 'hrmn', 'lum', 'agg', 'int', 'atm', 'col', 'dep', 'com', 'insee', 'adr', 'lat', 'long', 'code_postal', 'num', 'coordonnees', 'pr', 'surf', 'v1', 'circ', 'vosp', 'env1', 'voie', 'larrout', 'v2', 'lartpc', 'nbv', 'catr', 'pr1', 'plan', 'prof', 'infra', 'situ', 'an_nais', 'sexe', 'actp', 'grav', 'secu', 'secu_utl', 'locp', 'num_veh', 'place', 'catu', 'etatp', 'trajet', 'choc', 'manv', 'senc', 'obsm', 'obs', 'catv', 'occutc', 'gps', 'date', 'year_georef', 'com_name', 'dep_code', 'dep_name', 'epci_code', 'epci_name', 'reg_code', 'reg_name', 'com_arm_name', 'code_com']\n",
      "\n",
      "Nettoyage et conversion des types de donn√©es...\n",
      "Types de donn√©es convertis avec succ√®s.\n",
      "\n",
      "Nouveaux types de donn√©es (√©chantillon) :\n",
      "datetime    datetime64[ns, UTC]\n",
      "lat                     float64\n",
      "an                        Int64\n",
      "an_nais                   Int64\n",
      "dtype: object\n",
      "\n",
      "D√©but du chargement dans la couche SILVER...\n",
      "Structure de la table 'silver.accidents_cleaned' cr√©√©e.\n",
      "\n",
      "‚úÖ Succ√®s ! La table 'silver.accidents_cleaned' a √©t√© cr√©√©e et remplie.\n",
      "La couche Silver est maintenant pr√™te pour l'analyse et la construction de la couche Gold.\n"
     ]
    }
   ],
   "source": [
    "# =====================================================================\n",
    "# BLOC DE TRANSFORMATION : DE BRONZE VERS SILVER\n",
    "# Objectif : Renommer les colonnes et nettoyer les types de donn√©es.\n",
    "# =====================================================================\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import io\n",
    "\n",
    "print(\"D√©but du processus de transformation Bronze -> Silver...\")\n",
    "\n",
    "# --- PARTIE 1 : V√âRIFICATION DE LA CONNEXION ---\n",
    "# On s'assure que l'objet 'engine' existe bien depuis les cellules pr√©c√©dentes.\n",
    "if 'engine' not in locals():\n",
    "    print(\"Recr√©ation de l'objet de connexion 'engine'...\")\n",
    "    DB_USER = \"user_se_curite_routiere\"\n",
    "    DB_PASSWORD = \"password123\"\n",
    "    DB_HOST = \"localhost\"\n",
    "    DB_PORT = \"5432\"\n",
    "    DB_NAME = \"securite_routiere_db\"\n",
    "    DATABASE_URL = f'postgresql+psycopg2://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}'\n",
    "    engine = create_engine(DATABASE_URL)\n",
    "else:\n",
    "    print(\"Utilisation de l'objet de connexion 'engine' existant.\")\n",
    "\n",
    "\n",
    "# --- PARTIE 2 : LECTURE DES DONN√âES DE LA COUCHE BRONZE ---\n",
    "try:\n",
    "    print(\"\\nLecture des donn√©es depuis la table 'bronze.accidents_raw'...\")\n",
    "    # pd.read_sql_table est la fonction la plus simple pour lire une table enti√®re\n",
    "    df_bronze = pd.read_sql_table('accidents_raw', engine, schema='bronze')\n",
    "    print(f\"{df_bronze.shape[0]:,} lignes lues avec succ√®s.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erreur lors de la lecture de la table bronze : {e}\")\n",
    "    # On arr√™te le script si la lecture √©choue, car la suite ne peut pas fonctionner.\n",
    "    raise\n",
    "\n",
    "\n",
    "# --- PARTIE 3 : RENOMMAGE DES COLONNES AVEC VOTRE DICTIONNAIRE ---\n",
    "# (Assurez-vous que la cellule contenant votre dictionnaire 'mapping_colonnes' a √©t√© ex√©cut√©e)\n",
    "if 'mapping_colonnes' in locals():\n",
    "    print(\"\\nRenommage des colonnes en utilisant le dictionnaire fourni...\")\n",
    "    \n",
    "    # On applique le renommage. L'argument 'errors=\"raise\"' arr√™tera le script si un nom de colonne du dictionnaire n'est pas trouv√© dans le DataFrame.\n",
    "    df_silver = df_bronze.rename(columns=mapping_colonnes, errors=\"raise\")\n",
    "    \n",
    "    print(\"Colonnes renomm√©es avec succ√®s.\")\n",
    "    # On affiche les nouvelles colonnes pour v√©rification\n",
    "    print(\"Nouveaux noms de colonnes :\", df_silver.columns.tolist())\n",
    "else:\n",
    "    print(\"‚ùå Erreur : Le dictionnaire 'mapping_colonnes' n'a pas √©t√© trouv√©. Veuillez ex√©cuter la cellule qui le d√©finit.\")\n",
    "    raise\n",
    "\n",
    "\n",
    "# --- PARTIE 4 : NETTOYAGE ET CONVERSION DES TYPES DE DONN√âES (CORRIG√â) ---\n",
    "print(\"\\nNettoyage et conversion des types de donn√©es...\")\n",
    "try:\n",
    "    # Dates et heures - On suit le conseil du warning en passant tout en UTC\n",
    "    df_silver['datetime'] = pd.to_datetime(df_silver['datetime'], errors='coerce', utc=True)\n",
    "    df_silver['date'] = pd.to_datetime(df_silver['date'], errors='coerce', utc=True)\n",
    "\n",
    "    # Coordonn√©es g√©ographiques (pas de changement ici)\n",
    "    df_silver['lat'] = pd.to_numeric(df_silver['lat'], errors='coerce')\n",
    "    df_silver['long'] = pd.to_numeric(df_silver['long'], errors='coerce')\n",
    "\n",
    "    # On convertit d'abord en num√©rique (ce qui cr√©e des NaN et passe la colonne en float)\n",
    "    # Ensuite, on convertit en Int64, qui est un type sp√©cial d'entier chez Pandas qui supporte les NaN.\n",
    "    integer_columns = ['an', 'mois', 'jour', 'an_nais', 'pr', 'pr1', 'v1']\n",
    "    for col in integer_columns:\n",
    "        # La conversion se fait en une seule ligne robuste\n",
    "        df_silver[col] = pd.to_numeric(df_silver[col], errors='coerce').astype('Float64').astype('Int64')\n",
    "        \n",
    "    print(\"Types de donn√©es convertis avec succ√®s.\")\n",
    "    # On peut afficher les types pour v√©rifier\n",
    "    print(\"\\nNouveaux types de donn√©es (√©chantillon) :\")\n",
    "    print(df_silver[['datetime', 'lat', 'an', 'an_nais']].dtypes)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Une erreur est survenue lors de la conversion des types : {e}\")\n",
    "    raise\n",
    "\n",
    "\n",
    "# --- PARTIE 5 : CHARGEMENT DANS LA COUCHE SILVER ---\n",
    "# On r√©utilise la fonction rapide avec COPY que vous avez valid√©e\n",
    "def copy_from_stringio(df, table_name, schema_name, connection):\n",
    "    buffer = io.StringIO()\n",
    "    # On g√®re correctement les NaN pour la conversion en CSV\n",
    "    df.to_csv(buffer, index=False, header=False, sep=';', na_rep='\\\\N') # '\\\\N' est le standard pour NULL\n",
    "    buffer.seek(0)\n",
    "    raw_connection = connection.raw_connection()\n",
    "    cursor = raw_connection.cursor()\n",
    "    full_table_name = f'\"{schema_name}\".\"{table_name}\"'\n",
    "    \n",
    "    # On vide la table avant de la remplir pour simuler un 'replace'\n",
    "    cursor.execute(f\"TRUNCATE TABLE {full_table_name} RESTART IDENTITY;\")\n",
    "    \n",
    "    # La commande COPY\n",
    "    cursor.copy_expert(\n",
    "        f\"\"\"COPY {full_table_name} FROM STDIN WITH (FORMAT CSV, DELIMITER ';', NULL '\\\\N')\"\"\",\n",
    "        buffer\n",
    "    )\n",
    "    raw_connection.commit()\n",
    "    cursor.close()\n",
    "\n",
    "try:\n",
    "    print(\"\\nD√©but du chargement dans la couche SILVER...\")\n",
    "    \n",
    "    # 1. Cr√©er la structure de la table silver avec les bons noms de colonnes et types\n",
    "    # Pandas va automatiquement d√©duire les types SQL √† partir des types du DataFrame (datetime -> TIMESTAMP, etc.)\n",
    "    df_silver.head(0).to_sql('accidents_cleaned', engine, schema='silver', if_exists='replace', index=False)\n",
    "    print(\"Structure de la table 'silver.accidents_cleaned' cr√©√©e.\")\n",
    "    \n",
    "    # 2. Charger les donn√©es en utilisant la m√©thode rapide\n",
    "    copy_from_stringio(df_silver, 'accidents_cleaned', 'silver', engine)\n",
    "\n",
    "    print(\"\\n‚úÖ Succ√®s ! La table 'silver.accidents_cleaned' a √©t√© cr√©√©e et remplie.\")\n",
    "    print(\"La couche Silver est maintenant pr√™te pour l'analyse et la construction de la couche Gold.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Une erreur est survenue pendant le chargement dans la couche Silver : {e}\")\n",
    "    raise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
