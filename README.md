# ğŸš¦ Brief 1 â€” Analyse des accidents corporels de la circulation en France

## ğŸ§­ Objectif du projet
Ce projet vise Ã  analyser les donnÃ©es relatives aux **accidents corporels de la circulation en France**, afin de comprendre :
- Les causes principales des accidents
- Les zones et pÃ©riodes les plus Ã  risque
- Les profils de conducteurs les plus impliquÃ©s
- Les variables dÃ©terminantes pour la gravitÃ© des accidents

Lâ€™objectif final est de produire des visualisations claires et des modÃ¨les prÃ©dictifs permettant de mieux anticiper et prÃ©venir les accidents.

---

## ğŸ“Š Parcours de traitement
1. **Ingestion & prÃ©paration**  
   - Connexion Ã  la base de donnÃ©es (PostgreSQL via `docker-compose.yml`).  
   - Extraction des donnÃ©es brutes (`bronze.accidents_raw`) et normalisation des colonnes (`ingestion/transformation_accident.ipynb`).  
   - Fonctions de pipeline rÃ©utilisables centralisÃ©es dans `utils/etl.py` et `utils/utils.py`.
2. **Stockage**  
   - CrÃ©ation des tables cibles (schÃ©ma *silver*) avec les scripts SQL de `stockage/`.  
   - Insertion des donnÃ©es nettoyÃ©es via les notebooks ou les fonctions dâ€™ETL.
3. **Analyse exploratoire**  
   - Notebooks dâ€™EDA dans `analyse/` et Ã©bauches de requÃªtes analytiques dans `analyse/analyses.sql`.  
   - Visualisations complÃ©mentaires conservÃ©es dans le dossier `EDA/`.
4. **ModÃ©lisation**  
   - Prototypes de modÃ¨les et expÃ©rimentations dans `modelisation/` (fait sur google drive).

---

## ğŸ—‚ï¸ Arborescence du dÃ©pÃ´t
```text
BRIEF_1_ACCIDENTS/
â”œâ”€ analyse/                 # RequÃªtes SQL et notebooks dâ€™analyse exploratoire
â”œâ”€ EDA/                     # Visualisations et donnÃ©es intermÃ©diaires
â”œâ”€ ingestion/               # Notebooks de pipeline et transformations
â”œâ”€ modelisation/            # ExpÃ©rimentations de modÃ¨les prÃ©dictifs
â”œâ”€ stockage/                # Scripts SQL pour les tables bronze/silver
â”œâ”€ utils/                   # Connexion base, helpers ETL, mapping de colonnes
â”œâ”€ docker-compose.yml       # Services PostgreSQL & dÃ©pendances
â”œâ”€ requirements.txt         # DÃ©pendances Python
â””â”€ README.md
```

---

## ğŸ› ï¸ Stack technique
- **Python 3.12**, `pandas`, `sqlalchemy`, `psycopg2` pour lâ€™ingestion et le nettoyage.
- **Jupyter Notebooks** pour lâ€™exploration et la documentation des traitements.
- **PostgreSQL** orchestrÃ© via Docker pour le stockage *bronze/silver*.
- Visualisation et analyses statistiques avec `matplotlib`, `seaborn`, `scikit-learn`, etc.


## ğŸ“Œ Notes complÃ©mentaires
- Adapter les paramÃ¨tres de connexion (host, port, utilisateurs) si la configuration Docker diffÃ¨re.  
- Les notebooks contiennent des cellules de contrÃ´le pour vÃ©rifier la qualitÃ© des donnÃ©es (doublons, valeurs manquantes, incohÃ©rences).

Bonne exploration !
